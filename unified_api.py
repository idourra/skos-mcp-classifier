#!/usr/bin/env python3
"""
üåü UNIFIED CLASSIFICATION API - API Unificada con Arquitectura Centralizada
==========================================================================
Nueva API que utiliza el sistema unificado de entrada/salida:
- Data Gateway para ingesta
- Processing Pipeline para procesamiento
- Output Manager para salidas
- Compatibilidad completa con API anterior
"""

from fastapi import FastAPI, HTTPException, Query, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import asyncio
import logging
from datetime import datetime

# Imports de la nueva arquitectura
from core.data_gateway import (
    DataRequest, DataSource, DataType, InputFormat, ProductInput, 
    data_gateway, process_product, process_product_batch
)
from core.output_manager import (
    OutputFormat, DeliveryMethod, deliver_classification_result,
    deliver_batch_results, deliver_error, output_manager
)
from core.processing_pipeline import (
    processing_pipeline, process_product_request, process_batch_request
)

# Imports para respuestas enriquecidas
from core.enhanced_models import (
    EnhancedClassificationResponse, BatchEnhancedResponse, 
    DetailLevel, EnhancedErrorResponse
)
from core.enhanced_classifier import enhanced_classifier

# Imports existentes para compatibilidad
from server.taxonomy_endpoints import taxonomy_router

logger = logging.getLogger(__name__)

app = FastAPI(
    title="üåü Unified SKOS Classification API",
    description="API unificada con arquitectura centralizada para clasificaci√≥n de productos SKOS",
    version="3.0.0"
)

# Incluir router de taxonom√≠as (mantener compatibilidad)
app.include_router(taxonomy_router, prefix="/taxonomies", tags=["Taxonomies"])

# === MODELOS PYDANTIC UNIFICADOS ===

class UnifiedProductRequest(BaseModel):
    """Request unificado para producto individual"""
    text: str = Field(..., description="Descripci√≥n del producto a clasificar", min_length=1)
    product_id: Optional[str] = Field(None, description="ID √∫nico del producto")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Metadatos adicionales")

class UnifiedBatchRequest(BaseModel):
    """Request unificado para lote de productos"""
    products: List[UnifiedProductRequest] = Field(..., description="Lista de productos", min_items=1, max_items=1000)
    batch_id: Optional[str] = Field(None, description="ID √∫nico del lote")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Metadatos del lote")

class UnifiedResponse(BaseModel):
    """Respuesta unificada del sistema"""
    success: bool = Field(..., description="Si el procesamiento fue exitoso")
    pipeline_id: str = Field(..., description="ID del pipeline de procesamiento")
    processing_time_ms: float = Field(..., description="Tiempo de procesamiento en milisegundos")
    data: Any = Field(..., description="Datos de respuesta")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Metadatos adicionales")

class UnifiedErrorResponse(BaseModel):
    """Respuesta de error unificada"""
    success: bool = Field(False, description="Siempre false para errores")
    error_code: str = Field(..., description="C√≥digo del error")
    error_message: str = Field(..., description="Mensaje del error")
    details: Dict[str, Any] = Field(default_factory=dict, description="Detalles adicionales")
    timestamp: datetime = Field(default_factory=datetime.now)

class SystemStats(BaseModel):
    """Estad√≠sticas del sistema unificado"""
    pipeline_stats: Dict[str, Any] = Field(..., description="Estad√≠sticas del pipeline")
    gateway_stats: Dict[str, Any] = Field(..., description="Estad√≠sticas del gateway")
    output_stats: Dict[str, Any] = Field(..., description="Estad√≠sticas de salida")
    uptime: str = Field(..., description="Tiempo de actividad")

# === ENDPOINTS PRINCIPALES ===

@app.get("/", response_model=Dict[str, Any])
async def root():
    """Informaci√≥n de la API unificada"""
    return {
        "message": "üåü Unified SKOS Classification API",
        "version": "3.1.0",
        "description": "API unificada con arquitectura centralizada y respuestas enriquecidas",
        "features": [
            "Data Gateway √∫nico para entrada",
            "Processing Pipeline centralizado", 
            "Output Manager unificado",
            "Respuestas enriquecidas con an√°lisis detallado",
            "Niveles configurables de detalle",
            "An√°lisis de confianza granular",
            "Alternativas y conceptos relacionados",
            "Compatibilidad completa con v2.x",
            "M√©tricas integradas",
            "Manejo robusto de errores"
        ],
        "endpoints": {
            "/classify": "Clasificar producto individual",
            "/classify/enhanced": "Clasificaci√≥n con respuesta enriquecida",
            "/classify/batch": "Clasificar lote de productos",
            "/classify/async": "Clasificaci√≥n as√≠ncrona", 
            "/stats": "Estad√≠sticas del sistema",
            "/health": "Estado del sistema",
            "/taxonomies/*": "Gesti√≥n de taxonom√≠as"
        }
    }

@app.get("/health")
async def health_check():
    """Verificaci√≥n de salud del sistema unificado"""
    try:
        # Verificar componentes principales
        gateway_ok = hasattr(data_gateway, 'process_request')
        pipeline_ok = hasattr(processing_pipeline, 'process')
        output_ok = hasattr(output_manager, 'deliver_output')
        
        all_ok = gateway_ok and pipeline_ok and output_ok
        
        return {
            "status": "healthy" if all_ok else "degraded",
            "timestamp": datetime.now().isoformat(),
            "components": {
                "data_gateway": "ok" if gateway_ok else "error",
                "processing_pipeline": "ok" if pipeline_ok else "error", 
                "output_manager": "ok" if output_ok else "error"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")

@app.post("/classify", response_model=UnifiedResponse)
async def classify_single_unified(
    request: UnifiedProductRequest,
    taxonomy: Optional[str] = Query(None, description="ID de taxonom√≠a espec√≠fica"),
    output_format: str = Query("json", description="Formato de salida: json, csv, excel"),
    include_metadata: bool = Query(True, description="Incluir metadatos detallados")
):
    """
    üéØ Clasificar producto individual usando arquitectura unificada
    
    Flujo completo: Data Gateway ‚Üí Processing Pipeline ‚Üí Output Manager
    """
    try:
        start_time = datetime.now()
        
        # Procesar a trav√©s del pipeline unificado
        result = await process_product_request(
            text=request.text,
            product_id=request.product_id,
            taxonomy_id=taxonomy
        )
        
        if result['success']:
            # Preparar respuesta unificada
            response_data = result['data']
            
            # Agregar metadatos si se solicita
            if include_metadata:
                response_data['processing_metadata'] = {
                    'pipeline_id': result['pipeline_id'],
                    'processing_time_ms': result['processing_time_ms'],
                    'taxonomy_used': taxonomy,
                    'api_version': '3.0.0'
                }
            
            return UnifiedResponse(
                success=True,
                pipeline_id=result['pipeline_id'],
                processing_time_ms=result['processing_time_ms'],
                data=response_data,
                metadata={
                    'format': output_format,
                    'total_time_ms': (datetime.now() - start_time).total_seconds() * 1000
                }
            )
        else:
            raise HTTPException(
                status_code=422,
                detail=UnifiedErrorResponse(
                    error_code="CLASSIFICATION_FAILED",
                    error_message="Error en clasificaci√≥n",
                    details={'errors': result.get('errors', [])}
                ).dict()
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en clasificaci√≥n unificada: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=UnifiedErrorResponse(
                error_code="INTERNAL_ERROR",
                error_message=f"Error interno del servidor: {str(e)}"
            ).dict()
        )

@app.post("/classify/batch", response_model=UnifiedResponse)
async def classify_batch_unified(
    request: UnifiedBatchRequest,
    taxonomy: Optional[str] = Query(None, description="ID de taxonom√≠a espec√≠fica"),
    output_format: str = Query("json", description="Formato de salida"),
    parallel_processing: bool = Query(True, description="Procesamiento paralelo")
):
    """
    üì¶ Clasificar lote de productos usando pipeline unificado
    
    Optimizado para grandes vol√∫menes con procesamiento paralelo opcional
    """
    try:
        start_time = datetime.now()
        
        # Convertir a formato para pipeline
        products_data = [
            {"text": p.text, "product_id": p.product_id}
            for p in request.products
        ]
        
        # Procesar lote a trav√©s del pipeline
        if parallel_processing and len(products_data) > 5:
            # Procesamiento paralelo para lotes grandes
            chunk_size = max(1, len(products_data) // 4)  # Dividir en 4 chunks
            chunks = [
                products_data[i:i + chunk_size] 
                for i in range(0, len(products_data), chunk_size)
            ]
            
            # Procesar chunks en paralelo
            tasks = [
                process_batch_request(chunk, taxonomy_id=taxonomy)
                for chunk in chunks
            ]
            
            chunk_results = await asyncio.gather(*tasks)
            
            # Consolidar resultados
            all_results = []
            total_successful = 0
            total_failed = 0
            
            for chunk_result in chunk_results:
                if chunk_result['success']:
                    all_results.extend(chunk_result['results'])
                    total_successful += chunk_result['summary']['successful']
                    total_failed += chunk_result['summary']['failed']
            
            result = {
                'success': True,
                'results': all_results,
                'summary': {
                    'total_processed': len(all_results),
                    'successful': total_successful,
                    'failed': total_failed,
                    'processing_mode': 'parallel'
                }
            }
        else:
            # Procesamiento secuencial
            result = await process_batch_request(products_data, taxonomy_id=taxonomy)
            result['summary']['processing_mode'] = 'sequential'
        
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        return UnifiedResponse(
            success=True,
            pipeline_id=f"batch_{request.batch_id or 'auto'}",
            processing_time_ms=processing_time,
            data=result,
            metadata={
                'batch_size': len(request.products),
                'processing_mode': result['summary']['processing_mode'],
                'taxonomy_used': taxonomy
            }
        )
        
    except Exception as e:
        logger.error(f"Error en lote unificado: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=UnifiedErrorResponse(
                error_code="BATCH_ERROR",
                error_message=f"Error procesando lote: {str(e)}"
            ).dict()
        )

@app.post("/classify/async")
async def classify_async_unified(
    request: UnifiedBatchRequest,
    background_tasks: BackgroundTasks,
    taxonomy: Optional[str] = Query(None, description="ID de taxonom√≠a espec√≠fica"),
    callback_url: Optional[str] = Query(None, description="URL para notificaci√≥n de completado")
):
    """
    üîÑ Clasificaci√≥n as√≠ncrona para lotes grandes
    
    Inicia procesamiento en background y retorna inmediatamente
    """
    try:
        # Generar ID √∫nico para seguimiento
        import uuid
        job_id = str(uuid.uuid4())
        
        # Agregar tarea al background
        background_tasks.add_task(
            _process_async_batch,
            job_id=job_id,
            products=request.products,
            taxonomy=taxonomy,
            callback_url=callback_url
        )
        
        return {
            "success": True,
            "job_id": job_id,
            "message": "Procesamiento iniciado en background",
            "estimated_completion": "5-10 minutos para lotes grandes",
            "status_endpoint": f"/status/{job_id}",
            "callback_url": callback_url
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error iniciando procesamiento as√≠ncrono: {str(e)}"
        )

@app.get("/stats", response_model=SystemStats)
async def get_system_stats():
    """üìä Estad√≠sticas completas del sistema unificado"""
    try:
        return SystemStats(
            pipeline_stats=processing_pipeline.get_stats(),
            gateway_stats={"message": "Gateway stats not implemented yet"},
            output_stats=output_manager.get_stats(),
            uptime="Sistema activo"  # Simplificado por ahora
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error obteniendo estad√≠sticas: {str(e)}"
        )

# === ENDPOINTS DE COMPATIBILIDAD ===

@app.post("/classify/products")  # Mantener compatibilidad con v2.x
async def classify_products_compatibility(
    request: dict,
    taxonomy: Optional[str] = Query(None)
):
    """üîÑ Endpoint de compatibilidad con API v2.x"""
    try:
        # Convertir formato v2.x a v3.0
        if "products" in request:
            unified_request = UnifiedBatchRequest(
                products=[
                    UnifiedProductRequest(
                        text=p.get("text", ""),
                        product_id=p.get("product_id")
                    )
                    for p in request["products"]
                ]
            )
            return await classify_batch_unified(unified_request, taxonomy)
        else:
            # Producto individual
            unified_request = UnifiedProductRequest(
                text=request.get("text", ""),
                product_id=request.get("product_id")
            )
            return await classify_single_unified(unified_request, taxonomy)
            
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error en compatibilidad: {str(e)}"
        )

# === FUNCIONES DE BACKGROUND ===

async def _process_async_batch(
    job_id: str,
    products: List[UnifiedProductRequest],
    taxonomy: Optional[str] = None,
    callback_url: Optional[str] = None
):
    """Procesar lote de forma as√≠ncrona"""
    try:
        logger.info(f"üîÑ Iniciando procesamiento as√≠ncrono {job_id}")
        
        # Simular procesamiento (aqu√≠ ir√≠a la l√≥gica real)
        await asyncio.sleep(2)  # Simular trabajo
        
        # Procesar usando pipeline unificado
        products_data = [
            {"text": p.text, "product_id": p.product_id}
            for p in products
        ]
        
        result = await process_batch_request(products_data, taxonomy_id=taxonomy)
        
        # Si hay callback URL, enviar notificaci√≥n
        if callback_url:
            # Aqu√≠ se implementar√≠a el env√≠o del webhook
            logger.info(f"üì§ Enviando resultado a {callback_url}")
        
        logger.info(f"‚úÖ Procesamiento as√≠ncrono {job_id} completado")
        
    except Exception as e:
        logger.error(f"‚ùå Error en procesamiento as√≠ncrono {job_id}: {str(e)}")

# === ENDPOINTS ENRIQUECIDOS ===

@app.post("/classify/enhanced", response_model=EnhancedClassificationResponse)
async def classify_enhanced_endpoint(
    request: UnifiedProductRequest,
    taxonomy: Optional[str] = Query(None, description="ID de taxonom√≠a espec√≠fica"),
    detail_level: str = Query("standard", description="Nivel de detalle: basic, standard, full, debug"),
    include_alternatives: bool = Query(True, description="Incluir conceptos alternativos"),
    include_related: bool = Query(True, description="Incluir conceptos relacionados")
):
    """
    üåü Endpoint de clasificaci√≥n enriquecida con an√°lisis detallado
    
    **Nueva funcionalidad v3.1:**
    - An√°lisis de confianza granular con desglose detallado
    - Alternativas de clasificaci√≥n con explicaciones
    - Conceptos relacionados en la taxonom√≠a
    - Razonamiento del proceso de decisi√≥n
    - Metadatos completos de procesamiento
    - Informaci√≥n de calidad y recomendaciones
    
    **Niveles de detalle disponibles:**
    - `basic`: Solo clasificaci√≥n principal
    - `standard`: Incluye alternativas y razonamiento b√°sico
    - `full`: Respuesta completa con todos los metadatos
    - `debug`: Informaci√≥n t√©cnica adicional para desarrollo
    """
    try:
        # Validar nivel de detalle
        try:
            detail_enum = DetailLevel(detail_level)
        except ValueError:
            detail_enum = DetailLevel.STANDARD
        
        # Ejecutar clasificaci√≥n enriquecida
        result = enhanced_classifier.classify_enhanced(
            text=request.text,
            product_id=request.product_id,
            taxonomy_id=taxonomy,
            detail_level=detail_enum
        )
        
        # Filtrar contenido seg√∫n flags
        if not include_alternatives:
            result.classification.alternatives = []
        if not include_related:
            result.classification.related_concepts = []
            
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error en clasificaci√≥n enriquecida: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error en clasificaci√≥n enriquecida: {str(e)}"
        )

@app.post("/classify/batch/enhanced", response_model=BatchEnhancedResponse)
async def classify_batch_enhanced_endpoint(
    request: UnifiedBatchRequest,
    taxonomy: Optional[str] = Query(None, description="ID de taxonom√≠a espec√≠fica"),
    detail_level: str = Query("standard", description="Nivel de detalle para todos los productos"),
    max_concurrent: int = Query(5, description="M√°ximo procesamiento concurrente", ge=1, le=10)
):
    """
    üöÄ Clasificaci√≥n enriquecida en lotes con procesamiento optimizado
    
    Procesa m√∫ltiples productos con respuestas enriquecidas, optimizado para
    rendimiento con procesamiento concurrente controlado.
    """
    try:
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        # Validar nivel de detalle
        try:
            detail_enum = DetailLevel(detail_level)
        except ValueError:
            detail_enum = DetailLevel.STANDARD
        
        batch_id = f"batch_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        
        # Funci√≥n para procesar producto individual
        def process_single_product(product_request):
            try:
                return enhanced_classifier.classify_enhanced(
                    text=product_request.text,
                    product_id=product_request.product_id,
                    taxonomy_id=taxonomy,
                    detail_level=detail_enum
                )
            except Exception as e:
                logger.error(f"Error procesando {product_request.product_id}: {str(e)}")
                return None
        
        # Procesamiento concurrente
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
            results = list(executor.map(process_single_product, request.products))
        
        # Filtrar resultados exitosos y fallidos
        successful_results = [r for r in results if r is not None]
        failed_count = len(results) - len(successful_results)
        
        # Agregar costos (simplificado)
        total_cost = sum(r.processing.ai_interaction.cost_info.total_usd 
                        for r in successful_results)
        
        processing_time = (time.time() - start_time) * 1000
        
        return BatchEnhancedResponse(
            total=len(request.products),
            successful=len(successful_results),
            failed=failed_count,
            results=successful_results,
            batch_id=batch_id,
            processing_summary={
                "total_duration_ms": processing_time,
                "concurrent_workers": max_concurrent,
                "average_time_per_product": processing_time / len(request.products) if request.products else 0
            },
            aggregated_costs=CostInfo(
                total_usd=total_cost,
                breakdown=CostBreakdown(
                    prompt_tokens=sum(r.processing.ai_interaction.cost_info.breakdown.prompt_tokens 
                                    for r in successful_results),
                    completion_tokens=sum(r.processing.ai_interaction.cost_info.breakdown.completion_tokens 
                                        for r in successful_results),
                    total_tokens=sum(r.processing.ai_interaction.cost_info.breakdown.total_tokens 
                                   for r in successful_results)
                ),
                cost_per_token=CostPerToken(input=0.00000015, output=0.0000006)
            ),
            detail_level=detail_enum
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error en clasificaci√≥n en lotes enriquecida: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error en procesamiento de lotes: {str(e)}"
        )

@app.get("/classify/enhanced/formats")
async def get_enhanced_formats():
    """Obtener informaci√≥n sobre formatos de respuesta enriquecida disponibles"""
    return {
        "detail_levels": {
            "basic": {
                "description": "Solo clasificaci√≥n principal y confianza",
                "includes": ["concept_uri", "prefLabel", "confidence", "product_id"],
                "response_size": "M√≠nimo"
            },
            "standard": {
                "description": "Incluye alternativas y razonamiento b√°sico",
                "includes": ["clasificaci√≥n principal", "alternativas", "razonamiento", "metadatos b√°sicos"],
                "response_size": "Medio"
            },
            "full": {
                "description": "Respuesta completa con todos los metadatos",
                "includes": ["todo lo anterior", "conceptos relacionados", "an√°lisis de procesamiento", "m√©tricas de calidad"],
                "response_size": "Completo"
            },
            "debug": {
                "description": "Informaci√≥n t√©cnica adicional para desarrollo",
                "includes": ["todo lo anterior", "detalles t√©cnicos", "informaci√≥n de debugging"],
                "response_size": "M√°ximo"
            }
        },
        "compatibility": {
            "legacy_format": "Disponible en campo 'legacy_format'",
            "backward_compatible": "Mantiene compatibilidad total con v2.x"
        },
        "features": {
            "confidence_analysis": "An√°lisis granular de confianza con factores explicativos",
            "alternatives": "Hasta 3 conceptos alternativos con explicaciones",
            "related_concepts": "Conceptos relacionados en jerarqu√≠a taxon√≥mica",
            "reasoning": "Razonamiento detallado del proceso de decisi√≥n",
            "quality_metrics": "M√©tricas de calidad de entrada y procesamiento",
            "recommendations": "Recomendaciones autom√°ticas basadas en confianza"
        }
    }

# === MANEJO DE ERRORES GLOBAL ===

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """Manejo global de excepciones"""
    logger.error(f"‚ùå Error no manejado: {str(exc)}")
    
    # Entregar error usando Output Manager
    error_result = await deliver_error(
        error_code="UNHANDLED_ERROR",
        error_message=str(exc),
        details={"request_path": str(request.url.path)}
    )
    
    return HTTPException(
        status_code=500,
        detail=error_result.delivery_info if error_result.success else "Error cr√≠tico del sistema"
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)